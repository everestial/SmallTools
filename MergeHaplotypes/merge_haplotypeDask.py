#!/home/bin/python

print('\nChecking required modules\n')

import argparse
from functools import reduce
import time
import resource
import re
import sys
import os
import shutil
import dask.dataframe as pd
from glob import glob
import subprocess


''' Purpose of the program: Used to merge the haplotype file generated by phase-Extender
and phase-Stitcher. '''

start01 = time.time()


''' Call input and output argument variable names'''

def main():

    ''' Define required argument for interactive mode program. '''
    parser = argparse.ArgumentParser()

    parser.add_argument("--hapList",
                        help="name of the file that contains list of path to haplotype files obtained from phase-Extender.",
                        required=False)

    parser.add_argument("--f1List",
                        help="name of the file that contains list of the path to F1 hybrid haplotype files obtained "
                             "from phase-Stitcher.",
                        required=False)

    parser.add_argument("--f1ParentIDs",
                        help="comma separated names of the column header that indicates paternal haplotype "
                             "vs. maternal haplotype in F1 hybrids haplotypes. "
                             "Only required if 'f1List' is reported. ",
                        required=False)

    parser.add_argument("--output",
                        help="Directory name to store the merged haplotype file.",
                        required=True)

    global args;
    args = parser.parse_args()
    global pat_hap
    global mat_hap

    ## Assign the argument variables
    hap_paths = args.hapList
    f1_paths = args.f1List
    output = args.output


    if args.f1ParentIDs != None:
        pat_hap = args.f1ParentIDs.split(',')[0] + '_hap'
        mat_hap = args.f1ParentIDs.split(',')[1] + '_hap'
    else:
        pat_hap = 'pat_hap'
        mat_hap = 'mat_hap'


    #Create an output directory
    if os.path.exists(output):
        shutil.rmtree(output, ignore_errors=False, onerror=None)
    os.makedirs(output, exist_ok=True)


    with open(output + '/merged_haplotype.txt', 'w+') as fileout:

        if hap_paths == None and f1_paths == None:
            print("Haplotype files from both phase-Stitcher and phase-Extender are missing.")
            print("Provide HAPLOTYPE files from at least one category.")
            print()
            sys.exit()

        else:
            if hap_paths != None:
                hap_list = open(hap_paths, 'r')
                print('Reading HAPLOTYPE files obtained from phase-Extender')

            if f1_paths != None:
                f1_list = open(f1_paths, 'r')
                print('Reading HAPLOTYPE files obtained from phase-Stitcher')


        pd_df_list = []  # to store dataframes


        '''Now, pipe the list to function, that will extract required information. '''


        print('## Reading the haplotype files')
        print()
        '''Step 01: Now, read each haplotype file using pandas dataframe. 
                    ** - possible future upgrade using sqlite. '''

        ## from regular haplotype obtained from phase-Extender
        if hap_paths != None:
            pd_df_list = extract_haplotype(hap_list, pd_df_list, list_type='phaseExt')

        ## from regular haplotype obtained from phase-Stitcher
        if f1_paths != None:
            pd_df_list = extract_haplotype(f1_list, pd_df_list, list_type='phaseStc')


        print()
        ''' Step 02: Merging the dataframe '''
        print('Merging all the haplotype files together')
        pd_df_merged = reduce(lambda left, right: pd.merge(
           left, right, on=['CHROM', 'POS', 'REF', 'all-alleles'],
            how='outer'), pd_df_list) .fillna('.')

        ## ** if "concat" is required
        #df_by_dask_merged = dd.concat(dask_df)



        ''' Step 03: Write data to file (single or multiple) '''

        ## 03 - A: find the unique CHROM values, column names and group the df by index (CHROM)
        ## Store header information from all the merged dataframe
        dask_cols = '\t'.join(list(pd_df_merged.columns))


        # Write the dataframe to file. Dask write dataframes in chunks so we have "*"
        pd_df_merged.to_csv(output +'/daskdf*.txt', sep='\t', index=False, header=True)

        ## Merging the splitted datachunks using glob
        filenames = glob(output + '/daskdf*.txt')
        with open(output + '/daskdf_merged.txt', 'w') as out:
            for fn in filenames:
                with open(fn) as f:
                    out.write(''.join(f.readlines()[1:]))


        ## Now, sort the merged file
        # SHELL command: sort -k1,2 -V final_merged.txt > merged-sort.txt
        my_cmd = ["sort", "-k1,2", "-V", output +"/daskdf_merged.txt"]
        with open(output + '/mergedAndSortedDf.txt', 'w') as sort_data:
            sort_data.write(dask_cols + '\n')
            sort_data.flush()
            subprocess.run(my_cmd, stdout=sort_data)

            # remove the chunked pieces of daskdataframe that was written
            #subprocess.run(["rm", output + "/*daskdf*"])


        # remove files
        filenames = glob(output + '/daskdf*.txt', )
        for fn in filenames:
            os.remove(fn)


        print()
        print('merge and sort complete')
        print()
        print('  - Worker maximum memory usage : %.2f (mb)' % (current_mem_usage()))

    print('Global maximum memory usage: %.2f (mb)' % current_mem_usage())
    print('elapsed time: ', time.time()-start01)


def extract_haplotype(list_names, pd_df_list, list_type):
    for names in list_names:
        names = names.rstrip('\n')

        # Reading dataframe using dask (if file it too large)
        #df_by_pd = pd.read_csv(names, sep='\t', dtype={"CHROM": str, "POS": int})
        df_by_pd = pd.read_csv(names, sep='\t', dtype={"CHROM": str, "POS": int})


        # assign the SAMPLE:PI columns as string type
        for cols in list(df_by_pd.columns):
            if ":" in cols:
                #df_by_pd[cols] = df_by_pd[cols].apply(lambda x: str(x))
                df_by_pd = df_by_pd.astype({cols: 'object'})

        ### find the sample name
        column_names = list(df_by_pd.columns)
        sample_name = [x for x in column_names if x.endswith(':PI')]
        sample_name = [x.split(':')[0] for x in sample_name]
        sample_name = ','.join(sample_name)
        print('Sample name: %s ' % sample_name)


        print('Dropping columns and appending the pandas to a list')
        if 'all-freq' in df_by_pd.columns:
            df_by_pd = df_by_pd.drop(['all-freq'], axis=1)

        if 'log2odds' in df_by_pd.columns:
            df_by_pd = df_by_pd.drop(['log2odds'], axis=1)

        if 'lods' in df_by_pd.columns:
            df_by_pd = df_by_pd.drop(['lods'], axis=1)



        ''' for the haplotypes that are from "F1-Hybrids" we need to change the
        format a little bit. It should have GT,former PI-PG, new PI-PG. '''
        if list_type == 'phaseStc':
            print('Using F1 haplotype')

            ### first find the sample name
            column_names = list(df_by_pd.columns)
            sample_name = [x for x in column_names if x.endswith(':PI')]
            sample_name = [x.split(':')[0] for x in sample_name]
            sample_name = ','.join(sample_name)
            #print('Sample name: %s ' % sample_name)

            # drop the non required column
            df_by_pd = df_by_pd.drop([sample_name + ':PI'], axis=1)


            ''' Update the column values '''
            # ** Note: the column names assignment i.e "mat_hap" might change in the future.
            df_by_pd[sample_name + ':PG_al'] = df_by_pd[pat_hap] + '|' + df_by_pd[mat_hap]


            ## further update the ":PG_al" values
            df_by_pd[sample_name + ':PG_al'] = df_by_pd[sample_name + ':PG_al'].\
                apply(lambda x: '.' if "N" in x else x, meta=(sample_name + ':PG_al', 'str'))

            # update the phase index by CHROM or "."
            #df_by_pd[sample_name + ':PI'] = '.' if df_by_pd[sample_name + ':PG_al'] == '.' else df_by_pd(['CHROM'])
            df_by_pd[sample_name + ':PI'] = df_by_pd['CHROM'].\
                apply(lambda x: '.' if '.' in df_by_pd[sample_name + ':PG_al'] else x, meta=(sample_name + ':PI', 'str'))

            # Drop the non-required columns
            df_by_pd = df_by_pd.drop([pat_hap], axis=1)
            df_by_pd = df_by_pd.drop([mat_hap], axis=1)



        ## append the dataframe to a list
        pd_df_list.append(df_by_pd)

        # measuring memory
        print('  - Worker maximum memory usage : %.2f (mb)' % (current_mem_usage()))
        print()

    return pd_df_list






''' to monitor memory '''
def current_mem_usage():
    return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024.


## ** deprecated - use for alpha-numeric sorting in the future.
'''function for name sorting while reading file.
   - This function helps to read the file in alpha-numerical order when multiprocessing. '''
def numericalSort(value):
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    numbers = re.compile(r'(\d+)')

    return parts



if __name__ == '__main__':
    main()




